{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load and Preprocess Datasets\n",
    "\n",
    "# Load stock_price_dataset.csv\n",
    "stock_price_df = pd.read_csv('stock_price_dataset.csv')\n",
    "\n",
    "# Load upload_DJIA_table.csv\n",
    "djia_df = pd.read_csv('upload_DJIA_table.csv')\n",
    "\n",
    "# Rename columns to ensure consistency (if needed)\n",
    "stock_price_df.rename(columns={'Adj Close': 'Adj_Close'}, inplace=True)\n",
    "djia_df.rename(columns={'Adj Close': 'Adj_Close'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the correct datetime format explicitly\n",
    "stock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'], format='%y-%m-%d')\n",
    "djia_df['Date'] = pd.to_datetime(djia_df['Date'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge datasets (if necessary)\n",
    "\n",
    "# Merge stock_price_df with djia_df on 'Date' column (assuming they contain related information)\n",
    "merged_df = pd.merge(stock_price_df, djia_df, on='Date', how='outer', suffixes=('_stock', '_djia'))\n",
    "# Display information about merged DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date-related features\n",
    "merged_df['Day'] = merged_df['Date'].dt.day\n",
    "merged_df['Month'] = merged_df['Date'].dt.month\n",
    "merged_df['Year'] = merged_df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Prepare Data for Model Training\n",
    "\n",
    "# Select relevant features and target variable (Close price)\n",
    "features = ['Open_stock', 'High_stock', 'Low_stock', 'Volume_stock','Close_stock','Year','Month','Day']\n",
    "target = 'Close_stock'  # Target variable\n",
    "\n",
    "X = merged_df[features]\n",
    "y = merged_df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 8)\n",
      "(6680,)\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrame to exclude rows with NaN values in selected columns\n",
    "merged_df_clean = merged_df.dropna(subset=features + [target])\n",
    "print(X.shape)  # Should not be (0, num_features)\n",
    "print(y.shape)  # Should not be (0,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Split Data into Training and Test Sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer instance\n",
    "imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or 'most_frequent'\n",
    "\n",
    "# Fit the imputer on X_train to learn the imputation parameters\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test using the learned imputation parameters\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values from X_train and align y_train accordingly\n",
    "X_train_clean = X_train.dropna()\n",
    "y_train_clean = y_train.loc[X_train_clean.index]  # Match y_train indices with cleaned X_train indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:\n",
      "      Close_stock  Close_stock\n",
      "1501       103.28       103.28\n",
      "2586        78.83        78.83\n",
      "2653       136.87       136.87\n",
      "1055        53.80        53.80\n",
      "705         56.55        56.55\n",
      "\n",
      "Predicted:\n",
      "[[106.25606552 106.25606552]\n",
      " [ 78.79810927  78.79810927]\n",
      " [137.44301063 137.44301063]\n",
      " [ 51.98596264  51.98596264]\n",
      " [ 57.57880823  57.57880823]]\n",
      "Test R-squared: 0.9988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have defined `X` and `y` with features and target\n",
    "features = ['Open_stock', 'High_stock', 'Low_stock', 'Volume_stock','Year','Month','Day']\n",
    "target = 'Close_stock'\n",
    "\n",
    "# Combine features and target into a single DataFrame\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Drop rows with NaN values in the target column (Close_stock)\n",
    "data_clean = data.dropna(subset=[target])\n",
    "\n",
    "# Split data into features (X) and target (y) again after cleaning\n",
    "X_clean = data_clean[features]\n",
    "y_clean = data_clean[target]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define preprocessing steps within a pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('imputer', SimpleImputer(strategy='mean'), features)  # Impute missing values in specified features\n",
    "])\n",
    "\n",
    "# Define the full pipeline including preprocessing and model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on X_train and y_train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the filtered test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print actual and predicted values for comparison\n",
    "print(\"Actual:\")\n",
    "print(y_test[:5])  # Print first 5 actual values\n",
    "print(\"\\nPredicted:\")\n",
    "print(y_pred[:5])  # Print first 5 predicted values\n",
    "\n",
    "\n",
    "\n",
    "pickle_out = open('predict_talha.pkl','wb')\n",
    "pickle.dump(model,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "# Calculate R-squared scores\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test R-squared: {test_r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared: 0.9988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate R-squared scores\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test R-squared: {test_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
